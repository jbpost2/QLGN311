---
title: GN 311, June 2020
header-includes:
- \usepackage{xcolor}
- \usepackage{fontspec}
output:
  html_document:
    toc: true
    toc_float: true 
    number_sections: true
    fig_width: 8.5
    fig_height: 5.5
  pdf_document:
    latex_engine: xelatex
  word_document: default
---

<style type="text/css">

body{ /* Normal  */
      font-size: 14px;
  }
td {  /* Table  */
  font-size: 11px;
}
h1.title {
  font-size: 38px;
  color: #CC0000;
}
h1 { /* Header 1 */
  font-size: 24px;
  color: #2774AE;
}
h2 { /* Header 2 */
    font-size: 18px;
  color: #003B5C;
}
h3 { /* Header 3 */
  font-size: 16px;
  color: #003B5C;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

\setmainfont{Arial}

```{r,echo=F,include=F}
library(gridExtra)
```

```{r, include=F ,echo=F}
source("GN311_updated.R")
```

# What are the highest math classes that students took? {.tabset}

As seen in the graph and table in the tabs below, the most frequent highest math course taken is `MTH 231` in both 2019 and 2020. This course represents 36.8% and 41.0% of the maximum math courses taken in 2019 and 2020, respectively, out of courses that range from `MTH 103` to `MTH 432`.  

## Highest Math Course Graph
```{r,echo=F}
p.maxMTH
#for poster
p.maxMTH.Poster
```

## Highest Math Course Table
```{r, echo=F}
t.maxMTH
```

# When did they take their highest math? {.tabset}
The heatmap displays the most frequent term in which the highest math class was taken, by year. The colors/values correspond to the counts/frequencies that are greater than the median count value (excluding zeros). The median frequency across all year and MTH course combinations for 2019 was 7 and was 6 for 2020 (excluding zeros). Most students took their highest math class within 4 semesters of taking GN 311. For GN 311 2019, the semester where most students took their highest MTH course was the 2018 Spring Term. For GN 311 2020, the 2019 Spring Term contained the highest frequencies of maximum MTH course taken.

NOTE: Students that may have taken their highest math class more than once are counted only once according to the semester in which their grade points were highest (which generally corresponds to the latest enrollment), and then by latest enrollment if grade points were the same across different semesters.

## Graphs of Highest Math by Year Taken 
```{r,echo=F}
g.whenMTH
```

## 2019 Table
```{r, echo=F}
t.whenMTH19
```

## 2020 Table
```{r, echo=F}
t.whenMTH20
```

# How many students have taken ST 311? (prior to enrollment in GN 311) {.tabset}
193 students took ST 311 prior to taking GN 311 in the fall of 2019. 213 students took ST 311 prior to taking GN 311 in the spring of 2020. This table excludes students that took ST 311 during their enrollment in GN 311. 

NOTE: Students that may have taken ST 311 more than once are counted only once according to the semester in which their grade points were highest (which generally corresponds to the latest enrollment), and then by latest enrollment if grade points were the same across different semesters.

## Table

```{r,echo=F}
t.ST311prior
```

# How many people are currently taking ST 311? (while enrolled in GN 311) {.tabset}

36 students were enrolled in ST 311 while taking GN 311 during the fall of 2019. 28 students are currently enrolled in ST 311 and GN 311 for the spring, 2020.

NOTE: Few students may have also taken ST 311 prior to current ST 311 course enrollment with respect to their GN 311 cohort.

## Table

```{r,echo=F}
t.CE
```

# What was the average GPA for ST 311? {.tabset}

The average GPA for students who took ST 311 and GN 311 during Fall 2019 (indicated by the 'Current (2019)' row) is 3.0. The average GPA for students who did not take (or are not taking) ST 311 concurrently with GN 311, in 2019 and 2020 (middle row), is 3.3. The overall average GPA including all students (see notes below) is 3.1.

## Table

```{r,echo=F}
t.ST
```

# How many students got Homework 1 question 10 correct? How many got Homework 2 question 9 correct? {.tabset}

The table below displays 2020 in blue. The counts and percentages of correct, incorrect, and 'No Record' responses are indicated in the columns below.

## Table

```{r,echo=F}
t.QC
```

# Does it make a difference whether someone has taken ST 311 or not as to whether they got question 10 or 9 correct? {.tabset}

## Table

Below is a frequency table for questions 9, 10 and both that tabulates correct, incorrect and no record responses by whether or not ST 311 was taken. The first two rows are for 2019 and the second two rows are for 2020.  These questions are prior to intervention in the spring 2020 semester so we would roughly expect to see the same trends across 2019 and 2020 assuming similar populations of students.

```{r,echo=F}
t.tST
```

## Significant Differences

Using a binomial glm model `logodds(BothCorrect) ~ HighestMTH + tookST311 + ST311current` did not yield any significant factors.

Marginal binomial models for the log odds of answering each separate question correctly, using whether or not a student has taken ST 311 as the factor of interest indicated no significant association of taking ST 311 and grades for 2019 on correct answers for each question and both combined. The same results were found for 2020 except for question 10 where the model indicates a significant association between taking ST 311 and correct answers at the .032 significane level using a Wald Test. However, the chi-square test does not indicate significance and accounting for the multiple tests, the association is not likely significant.  

'No Record' responses were excluded from these models. 

Below is the summary output for the binomial model coefficients for question 9 in 2019 along with the chi-square association test. The last two rows are the same models for question 9 in 2020. All other tests of interest are similar in that there is no evidence of statistically significant association between taking ST 311 on answer status.

```{r,echo=F}
A<-summary(g.binomQ919)
A$coefficients
summary(table(gn311$tookST311[gn311$year==2019],
                       gn311$Q9correct[gn311$year==2019]))

B<-summary(g.binomQ920)
B$coefficients
summary(table(gn311$tookST311[gn311$year==2020],
                       gn311$Q9correct[gn311$year==2020]))

```

# Analysis in regard to HW 6 questions

Intervention occurred between homework 2 and homework 6.  We want to look at any possible impact the intervention may have had.  There are a number of questions from homework 6 to consider here.  There are binary indicators of correct/incorrect for each and one summary average variable that aggregates across the questions. 



```{r, eval = FALSE, echo = FALSE}
select(full_data, Cohort, ends_with("bin")) %>% group_by(Cohort) %>% summarize_if(.predicate = function(x) is.numeric(x), .funs = funs(quantile), p = 0.25, na.rm = TRUE)
```

For all of the questions, ignoring missing values (students that didn't complete the question and students that didn't have a cohort) the first quartile of binary scores is 1.  This indicates that 75% of people got an individual question correct.  The sample proportion of correct responses for each question is given below as well as the summary stats on the aggregate variable.

```{r, warning = FALSE}
means <- full_data %>% group_by(Cohort) %>% select(Cohort, ends_with("bin")) %>% 
  summarize_if(.predicate = function(x) is.numeric(x), .funs = funs(mean="mean"), na.rm = TRUE) 
kable(means[1:2,], col.names = c("Cohort", paste("Q", c(3:10, 15:19)), "Aggregate"), digits = 3) %>% 
  kable_styling(bootstrap_options = "striped",full_width = T) 
#For poster:
kable(means[1:2,c(1,4:6, 12:15)], col.names = c("Cohort", paste("Q", c(5:7, 17:19)), "Aggregate"), digits = 3) %>% 
  kable_styling(bootstrap_options = "striped",full_width = T) 
```

Looking closely at the questions themselves, I'm going to remove question 8, 9, and 10 (Keeping all decimal digits during your calculations and rounding your answer to 3 decimal digits, what is the calculated chi-square value? What is the number for the degrees of freedom? What is the critical value?  Round to two decimal places.) as these weren't things focused on in the intervention.

```{r}
full_data <- select(full_data, -HW6_Q_8_score_bin, -HW6_Q_9_score_bin, - HW6_Q_10_score_bin)
```

Conducting a quick comparison of these sample proportions by question using a logistic regression model to get a p-value (assumptions likely not met but still somewhat useful).

```{r}
full_data <- full_data[!is.na(full_data$Cohort),]

#create indicator of math above 100 level or not
full_data$MTHLevel <- ifelse(full_data$MTHcourse > 200, "200's", "100's")

sum_glm <- function(data, response){ 
  fit <- glm(data[[response]] ~ Cohort, data = data)
  means <- aggregate(data[[response]] ~ Cohort, data = data, FUN = mean)
  resp <- gregexpr(response, pattern = "(Q_\\d+)")
  ret <- c(substring(response, resp[[1]], resp[[1]]+attr(resp[[1]],'match.length')-1), round(c(fit$coefficients, means[,2], means[2,2]-means[1,2], summary(fit)$coefficients[2,4]), 4))
  names(ret) <- c("Response", "Intercept", "Beta1", "2019 mean", "2020 mean", "Difference", "p-value")
  ret
}

bin_names <- c("HW6_Q_3_score_bin", "HW6_Q_4_score_bin", "HW6_Q_5_score_bin",
               "HW6_Q_6_score_bin", "HW6_Q_7_score_bin",  "HW6_Q_15_score_bin",
               "HW6_Q_16_score_bin", "HW6_Q_17_score_bin", "HW6_Q_18_score_bin",
           "HW6_Q_19_score_bin")
lapply(X = bin_names, FUN = sum_glm, data = full_data)
```

Three of these are significant or marginally signficant and in the direction we'd hope for.  That's a good sign.  

We'll also consider just the students that missed at least one question from the earlier homework assignment.  Perhaps they are the ones that will show improvement.  

```{r}
#filter by missing an earlier question or having no record
missed_data <- filter(full_data, bothQscorrect != 1)
lapply(X = bin_names, FUN = sum_glm, data = missed_data)
```

Looking like just the last two questions showed improvement (none went the wrong way) when averaged across things.  

# HW 6 Q's broken down - all students 

To further investigate the effect of the intervention we'll look at a break down comparing cohorts for correct/incorrect question status by things like:  

+ highest math course taken (>200 or <200)  (`MTHLevel`)
+ ST 311 status (not taken or taken) (`tookST311`)  
+ class level (senior, etc.) (`NC_LVL_BOT_DESCR`)
+ race (`STDNT_RACE_IPEDS`)  
+ sex (`STUDENT_GENDER_IPEDS`)   
+ transfer status (`ORIG_ENROLL_STATUS`)
+ rural status(`RuralStatus`)
+ first gen status (`FirstGenStatus`)

First just the means across some combinations.

```{r, echo = FALSE}
q_means <- function(data, response, preds){
   ag1 <- aggregate(as.formula(paste0(response, "~", paste(preds, collapse = "+"))), data = data, FUN = mean)
   ag2 <- aggregate(as.formula(paste0(response, "~", paste(preds, collapse = "+"))), data = data, FUN = length)
   temp <- cbind(ag1, ag2[,ncol(ag2)])
   resp <- gregexpr(response, pattern = "(Q_\\d+)")
   names(temp)[(ncol(temp)-1):ncol(temp)] <- paste0(  substring(response, resp[[1]], resp[[1]]+attr(resp[[1]],'match.length')-1), c("Mean", "Count"))
   return(temp)
}

# q_means <- function(data, response, preds){
#   ag1 <- aggregate(as.formula(paste0(response, "~", paste(preds, collapse = "+"))), data = data, FUN = mean)
#   ag2 <- aggregate(as.formula(paste0(response, "~", paste(preds, collapse = "+"))), data = data, FUN = length)
#   temp <- cbind(ag1, ag2[,ncol(ag2)])
#   resp <- gregexpr(response, pattern = "(Q_\\d)")
#   names(temp)[(ncol(temp)-1):ncol(temp)] <- paste(  substring(response, resp[[1]], resp[[1]]+attr(resp[[1]],'match.length')-1), c("Avg", "n"))
#   temp <- temp %>% pivot_wider(names_from = Cohort, values_from = names(temp)[(nrow(temp)-1):nrow(temp)])
#   #temp$Diff <- temp[,ncol(temp)-2] - temp[, ncol(temp)-3]
#   return(temp)
# }

nice_it <- function(out){
 temp <- out %>% pivot_wider(names_from = Cohort, values_from = starts_with("Q")) 
 temp$Diff <- round(temp[,(ncol(temp)-2)] - temp[,(ncol(temp)-3)], 3)
 temp
}

qs <- c(3:10, 15:19)

preds <- c("Cohort", "MTHLevel", "tookST311", "NC_LVL_BOT_DESCR", "STDNT_RACE_IPEDS", "STUDENT_GENDER_IPEDS", "ORIG_ENROLL_STATUS", "RuralStatus", "FirstGenStatus")
```

<!-- ## By Cohort, Math level, Class level, and Sex   -->

<!-- ```{r, results = "asis", echo = FALSE} -->
<!-- out1 <- lapply(X = bin_names, FUN = q_means, data = full_data, preds = preds[c(1,2,4,6)]) -->

<!-- out1e <- lapply(FUN = nice_it, X= out1) -->

<!-- for(x in 1:length(out1e)){ -->
<!--   print(kable(out1e[[x]], digits = 3, col.names = c("MathLevel", "Class", "Sex", "Avg2019", "Avg2020", "n2019", "n2020", "AvgDiff"), caption = paste0("Question ", qs[x], " Summary")) %>%  -->
<!--           kable_styling(bootstrap_options = "striped",full_width = T) ) -->
<!-- }  -->
<!-- ``` -->

## By Cohort, Math Level, Transfer, and First Gen  

```{r, results = "asis"}
out2 <- lapply(X = bin_names, FUN = q_means, data = full_data, preds = preds[c(1,2,7,9)])

out2e <- lapply(FUN = nice_it, X= out2)

for(x in 1:length(out2e)){
  print(kable(out2e[[x]], digits = 3, col.names = c("MathLevel", "Transfer", "First Gen", "Avg2019", "Avg2020", "n2019", "n2020", "AvgDiff"), caption = paste0("Question ", qs[x], " Summary")) %>% 
          kable_styling(bootstrap_options = "striped",full_width = T) )
} 
```

## BY Cohort, Math Level, and Rural status

```{r, results = "asis"}
out3 <- lapply(X = bin_names, FUN = q_means, data = full_data, preds = preds[c(1,2, 8)])

out3e <- lapply(FUN = nice_it, X= out3)

for(x in 1:length(out3e)){
  print(kable(out3e[[x]], digits = 3, col.names = c("MathLevel", "Rural", "Avg2019", "Avg2020", "n2019", "n2020", "AvgDiff"), caption = paste0("Question ", qs[x], " Summary")) %>% 
          kable_styling(bootstrap_options = "striped",full_width = T) )
} 
```


# HW 6 Q's broken down - incorrect HW 2


<!-- ## By Cohort, Math level, Class level, and Sex   -->

<!-- ```{r, results = "asis"} -->
<!-- out1 <- lapply(X = bin_names, FUN = q_means, data = missed_data, preds = preds[c(1,2,4,6)]) -->

<!-- out1e <- lapply(FUN = nice_it, X= out1) -->

<!-- for(x in 1:length(out1e)){ -->
<!--   print(kable(out1e[[x]], digits = 3, col.names = c("MathLevel", "Class", "Sex", "Avg2019", "Avg2020", "n2019", "n2020", "AvgDiff"), caption = paste0("Question ", qs[x], " Summary")) %>%  -->
<!--           kable_styling(bootstrap_options = "striped",full_width = T) ) -->
<!-- }  -->
<!-- ``` -->

## By Cohort, Math Level, Transfer, and First Gen  

```{r, results = "asis"}
out2 <- lapply(X = bin_names, FUN = q_means, data = missed_data, preds = preds[c(1,2,7,9)])

out2e <- lapply(FUN = nice_it, X= out2)

for(x in 1:length(out2e)){
  print(kable(out2e[[x]], digits = 3, col.names = c("MathLevel", "Transfer", "First Gen", "Avg2019", "Avg2020", "n2019", "n2020", "AvgDiff"), caption = paste0("Question ", qs[x], " Summary")) %>% 
          kable_styling(bootstrap_options = "striped",full_width = T) )
} 
```

## BY Cohort, Math Level, and Rural status

```{r, results = "asis"}
out3 <- lapply(X = bin_names, FUN = q_means, data = missed_data, preds = preds[c(1,2, 8)])

out3e <- lapply(FUN = nice_it, X= out3)

for(x in 1:length(out3e)){
  print(kable(out3e[[x]], digits = 3, col.names = c("MathLevel", "Rural", "Avg2019", "Avg2020", "n2019", "n2020", "AvgDiff"), caption = paste0("Question ", qs[x], " Summary")) %>% 
          kable_styling(bootstrap_options = "striped",full_width = T) )
} 
```

# Logistic Regression with Variable Selection

On the full data I'll do some automated variable selection just to see what variables pop out as useful.  

```{r}
full_fit <- function(data, response, preds){
  fit <- glm(as.formula(paste0(response, "~", "(", paste(preds, collapse = "*"), ")^2")), data = data, family = binomial)
  mod <- stepAIC(fit, scope = list(lower =~Cohort, upper = fit), trace = FALSE)
  summary(mod)
}


#remove NAs before use...
full_data <- full_data %>% filter(!is.na(FirstGenStatus))
full_data <- full_data %>% filter(!is.na(RuralStatus))
```

## Cohort, Math Level, and Transfer  

```{r}
lapply(X = bin_names, FUN = full_fit, data = full_data, preds = preds[c(1,2, 7)])
```

## Cohort, Math Level, and Rural Status  

```{r}
lapply(X = bin_names, FUN = full_fit, data = full_data, preds = preds[c(1,2, 8)])

```

## Cohort, Math Level, and First Gen

```{r}
lapply(X = bin_names, FUN = full_fit, data = full_data, preds = preds[c(1,2, 9)])

#quick summary of firstgen without unknown
temp <- full_data %>% filter(FirstGenStatus != "Unknown")

ggplot(temp, aes(x= as.factor(year))) + geom_bar(aes(fill = FirstGenStatus), position = "dodge") + xlab(label = "Cohort")

```

# Logistic rough conclusions

Cohort is reasonably important in quite a few of the models.  We are doing a lot of model fitting and tests so p-values aren't a great metric here but we are getting some evidence of an improvement by cohort.  Math level is also important in a good number of the models.  There are some interactions with cohort and the other variables that are significant here or there as well.  This would imply that the intervention might help certain groups more.  However, again, with all the testing it is hard to say that these are real results - encouraging to some degree though!  



# More poster stuff  

Things to make graphs/redo models for:

- Q5 selected model had Cohort (0.047) and MathLevel (0.03) both significant
With FirstGen, Cohort (0.04), MathLevel (0.02), and Not first gen vs 1st gen showed a positive effect (first gen did worse) (0.02)  

- Q6 and Q7 had the same but Cohort had p-values of about 0.1 (MathLevel about 0.05)  

    + Same as Q5 with first gen.  But Q7 also showed an interaction between firstgen and mathlevel
    
- Q17 selected model had cohort, mathlevel, first gen, many interactions are significant  

- Q18/Q19 had Cohort (0.01, 0.08, respectively)  

```{r}
full_fit <- function(data, response, preds){
  fit <- glm(as.formula(paste0(response, "~", "(", paste(preds, collapse = "*"), ")^2")), data = data, family = binomial)
  mod <- stepAIC(fit, scope = list(lower =~Cohort, upper = fit), trace = FALSE)
  summary(mod)
}


#remove NAs before use...
temp <- temp %>% filter(!is.na(FirstGenStatus))
temp <- temp %>% filter(!is.na(RuralStatus))
bin_names
lapply(X = bin_names[c(3:5, 8:10)], FUN = full_fit, data = temp, preds = preds[c(1,2, 9)])


response <- "HW6_Q_19_score_bin"
  fit <- glm(temp[[response]] ~ Cohort, data = temp)
  means <- aggregate(temp[[response]] ~ Cohort, data = temp, FUN = mean)
  resp <- gregexpr(response, pattern = "(Q_\\d+)")
  ret <- c(substring(response, resp[[1]], resp[[1]]+attr(resp[[1]],'match.length')-1), round(c(fit$coefficients, means[,2], means[2,2]-means[1,2], summary(fit)$coefficients[2,4]), 4))
  names(ret) <- c("Response", "Intercept", "Beta1", "2019 mean", "2020 mean", "Difference", "p-value")
ret

#summarize question 17 for poster
fit <- glm(temp[["HW6_Q_17_score_bin"]] ~ (Cohort*MTHLevel*FirstGenStatus)^2, data = temp, family = "binomial")
summary(fit)
cf <- fit$coefficients

SpringMTH200NotFirstGen <- sum(cf[1:8])
FallMTH200NotFirstGen <- sum(cf[c(1, 3, 4, 7)])
SpringNotMTH200NotFirstGen <- sum(cf[c(1,2,4,6,8)])
FallNotMTH200NotFirstGen <- sum(cf[c(1,4)])

SpringMTH200FirstGen <- sum(cf[c(1,2,3,5)])
FallMTH200FirstGen <- sum(cf[c(1,3)])
SpringNotMTH200FirstGen <- sum(cf[c(1,2)])
FallNotMTH200FirstGen <- sum(cf[c(1)])

myDF <- data.frame(Cohort = rep(c("Spring", "Fall"), 4), MathLevel = rep(c(rep(">200", 2), rep("<200",2)), 2), FirstGenStatus = c(rep("Not First", 4), rep("First", 4)), Estimate = 1/(1+exp(-c(SpringMTH200NotFirstGen,FallMTH200NotFirstGen , SpringNotMTH200NotFirstGen, FallNotMTH200NotFirstGen, SpringMTH200FirstGen,FallMTH200FirstGen,  SpringNotMTH200FirstGen, FallNotMTH200FirstGen))))

ggplot(data = myDF, aes(x=Cohort)) + geom_bar(stat = "identity", aes(y = Estimate, fill = MathLevel), position = "dodge")

#ggplot(data = myDF, aes(x=Cohort)) + geom_bar(stat = "identity", aes(y = Estimate, fill = MathLevel), position = "dodge") +facet_wrap(FirstGenStatus)

```


